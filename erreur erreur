import os, shutil, datetime, pandas as pd
from openpyxl import load_workbook
from openpyxl.workbook.properties import CalcProperties
from openpyxl.styles import Font, Border, PatternFill, Alignment, Protection
import openpyxl, openpyxl.utils
import concurrent.futures

# Parameters with validation
path_of_data = dbutils.widgets.get("path_of_data").strip()
environment = (dbutils.widgets.get("environment") or "DEV").strip()
user_email = dbutils.widgets.get("user").strip()
period = int(dbutils.widgets.get("periodSelected").strip().split('-')[1])

_to_bool = lambda name: dbutils.widgets.get(name).strip().lower() == "true"
currency_goc = _to_bool("currency_goc")
currency_rep = _to_bool("currency_rep")
all_gocs = _to_bool("all_gocs")
var_report = _to_bool("var_report")

# Aggregation levels
agg_level1 = _to_bool("agg_level1")
agg_level2 = _to_bool("agg_level2")
agg_level3 = _to_bool("agg_level3")
agg_level4 = _to_bool("agg_level4")
agg_level5 = _to_bool("agg_level5")

# Report flags
agg_reports = any([agg_level1, agg_level2, agg_level3, agg_level4, agg_level5])
var_report = all_gocs or agg_reports

run_date = dbutils.widgets.get("runDate").strip() or datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

template_dir = "Toolkit_Template_v1.xlsx"
support_dir = "VAR_Report_Formulas.csv"
output_path = dbutils.widgets.get("output_path")
if not os.path.exists(output_path):
  os.makedirs(output_path)

if not path_of_data or not os.path.exists(path_of_data):
    dbutils.notebook.exit(f"ERROR: inputs folder not found: {path_of_data}")
if not os.path.exists(template_dir):
    dbutils.notebook.exit(f"ERROR: Template file not found: {template_dir}")

def clean_columns(df):
    if df.empty:
        return df
    drop_cols = [col for col in ['UPDATE_DATE', 'Period', 'period', 'update_date'] if col in df.columns]
    return df.drop(columns=drop_cols) if drop_cols else df

def remove_suffix(df):
    df.columns = [col[:-2] if col.endswith('_2') else col for col in df.columns]
    return df

def create_aggregated_data(df_source, agg_level):
    """Create aggregated data for a specific level"""
    if df_source.empty:
        return pd.DataFrame()
    
    df_agg = df_source.copy()
    
    # Supprimer les colonnes d'agrégation non utilisées
    agg_cols_to_drop = []
    for i in range(1, 6):
        if i != agg_level:
            agg_cols_to_drop.extend([f'Aggreg_{i}_ID', f'Aggreg_{i}', f'Agg_{i}'])
    
    # Supprimer les colonnes qui existent
    existing_cols_to_drop = [col for col in agg_cols_to_drop if col in df_agg.columns]
    df_agg = df_agg.drop(columns=existing_cols_to_drop)
    
    # Supprimer la colonne Level si elle existe
    if 'Level' in df_agg.columns:
        df_agg = df_agg.drop(columns=['Level'])
    if 'level' in df_agg.columns:
        df_agg = df_agg.drop(columns=['level'])
    
    # Renommer la colonne d'agrégation choisie en Level
    agg_col_name = f'Aggreg_{agg_level}_ID'
    if agg_col_name in df_agg.columns:
        df_agg = df_agg.rename(columns={agg_col_name: 'Level'})
    else:
        # Essayer d'autres variantes
        for variant in [f'Aggreg_{agg_level}', f'Agg_{agg_level}']:
            if variant in df_agg.columns:
                df_agg = df_agg.rename(columns={variant: 'Level'})
                break
    
    # Grouper par iter, t, Level et faire la somme des colonnes numériques
    group_cols = ['iter', 't', 'Level']
    existing_group_cols = [col for col in group_cols if col in df_agg.columns]
    
    if existing_group_cols:
        # Identifier les colonnes numériques
        numeric_cols = df_agg.select_dtypes(include=['number']).columns.tolist()
        
        # Grouper et sommer
        df_agg = df_agg.groupby(existing_group_cols)[numeric_cols].sum().reset_index()
    
    return df_agg

    
def read_file_safe(file_info):
    subfolder, filename, run_date = file_info
    try:
        filepath = os.path.join(path_of_data, subfolder, f"{filename}_{run_date}.csv")
        if os.path.exists(filepath):
            return filename, pd.read_csv(filepath, low_memory=False, engine='c')
        else:
            return filename, pd.DataFrame()
    except Exception as e:
        return filename, pd.DataFrame()

def inject_data_efficient(ws, df, start_row=1, start_col=1):
    if df.empty:
        return
    
    try:
        df_clean = clean_columns(df)
        for j, col_name in enumerate(df_clean.columns):
            ws.cell(row=start_row, column=start_col + j, value=str(col_name))
        
        chunk_size = 500
        for chunk_start in range(0, len(df_clean), chunk_size):
            chunk_end = min(chunk_start + chunk_size, len(df_clean))
            chunk_data = df_clean.iloc[chunk_start:chunk_end]
            
            for i, (_, row) in enumerate(chunk_data.iterrows()):
                row_num = start_row + 1 + chunk_start + i
                for j, value in enumerate(row):
                    if pd.notna(value):  
                        ws.cell(row=row_num, column=start_col + j, value=value)
    except Exception:
        pass

def safe_inject(wb, ws_name, df, row=1, col=1):
    try:
        if isinstance(df, pd.DataFrame) and not df.empty and ws_name in wb.sheetnames:
            inject_data_efficient(wb[ws_name], df, row, col)
    except Exception:
        pass

def copy_format_safe(source, target):
    try:
        target.font = Font(name=source.font.name, size=source.font.size, bold=source.font.bold,
                          italic=source.font.italic, color=source.font.color)
        target.border = Border(left=source.border.left, right=source.border.right, 
                              top=source.border.top, bottom=source.border.bottom)
        target.fill = PatternFill(fill_type=source.fill.fill_type, 
                                 start_color=source.fill.start_color, end_color=source.fill.end_color)
        target.number_format = source.number_format
    except Exception:
        pass

def get_mapping_value(df_mapping, row_idx, possible_cols, default='N/A'):
    try:
        row_data = df_mapping.iloc[row_idx]
        for col_name in possible_cols:
            if col_name in df_mapping.columns:
                value = row_data[col_name]
                if pd.notna(value) and str(value).strip():
                    return str(value)
        return default
    except Exception:
        return default

def create_var_report(wb, template, report_ref, curr_period, df_mapping, df_formulas):
    try:
        # Copy sheet
        source_sheet = wb[template]
        new_sheet = wb.copy_worksheet(source_sheet)
        new_sheet.title = f'VAR_{report_ref}_{curr_period}'
        new_sheet.cell(row=2, column=3).value = report_ref
        
        goc_count = len(df_mapping)
        var_col_start = openpyxl.utils.column_index_from_string('F')
        source_cell = wb[template].cell(row=5, column=var_col_start)
        
        batch_size = 100
        for batch_start in range(0, goc_count, batch_size):
            batch_end = min(batch_start + batch_size, goc_count)
            
            for i in range(batch_start, batch_end):
                col_idx = var_col_start + i
                
                new_sheet.cell(row=5, column=col_idx).value = get_mapping_value(df_mapping, i, ['iter'], '1')
                new_sheet.cell(row=6, column=col_idx).value = 1
                new_sheet.cell(row=7, column=col_idx).value = get_mapping_value(df_mapping, i, ['level', 'Level'], '1')
                
                agg_mappings = [
                    (8, ['Aggreg_1_ID', 'Aggreg_1', 'Agg_1']),
                    (9, ['Aggreg_2_ID', 'Aggreg_2', 'Agg_2']),
                    (10, ['Aggreg_3_ID', 'Aggreg_3', 'Agg_3']),
                    (11, ['Aggreg_4_ID', 'Aggreg_4', 'Agg_4']),
                    (12, ['Aggreg_5_ID', 'Aggreg_5', 'Agg_5'])
                ]
                
                for row_num, possible_cols in agg_mappings:
                    value = get_mapping_value(df_mapping, i, possible_cols, 'N/A')
                    cell = new_sheet.cell(row=row_num, column=col_idx)
                    cell.value = value
                    copy_format_safe(source_cell, cell)
                
                business_mappings = [
                    (13, ['Measurement_Model', 'Measurement', 'Model'], 'VFA'),
                    (14, ['OCI_Option', 'OCI', 'Option_OCI'], 'No'),
                    (15, ['GoC_Currency', 'GOC_Currency', 'Currency_GOC'], 'EUR'),
                    (16, ['Reporting_Currency', 'Rep_Currency', 'Currency_Rep'], 'EUR'),
                    (17, ['GoC_Type_Reinsurance', 'Type_Reinsurance', 'Reinsurance'], 'Gross')
                ]
                
                for row_num, possible_cols, default_val in business_mappings:
                    value = get_mapping_value(df_mapping, i, possible_cols, default_val)
                    cell = new_sheet.cell(row=row_num, column=col_idx)
                    cell.value = value
                    copy_format_safe(source_cell, cell)
                
                for row_num in [954, 955, 956]:
                    cell = new_sheet.cell(row=row_num, column=col_idx)
                    cell.value = 'No'
                    copy_format_safe(source_cell, cell)
                
                col_letter = openpyxl.utils.get_column_letter(col_idx)
                for _, formula_row in df_formulas.iterrows():
                    try:
                        formula = str(formula_row['All_Goc_Formula']).replace('Col', col_letter)
                        target_row = int(formula_row['Row_Index'])
                        target_cell = new_sheet.cell(row=target_row, column=col_idx)
                        target_cell.value = formula
                        copy_format_safe(source_cell, target_cell)
                    except Exception:
                        continue
    except Exception:
        pass

df_act_goc = pd.read_csv(os.path.join(path_of_data, "all_goc_actuarial_aom_goc_curr/all_goc_actuarial_aom_goc_curr_" + run_date + ".csv"))
df_ifrs_goc = pd.read_csv(os.path.join(path_of_data, "all_goc_ifrs17_aom_pnl_goc_curr/all_goc_ifrs17_aom_pnl_goc_curr_" + run_date + ".csv"))
df_act_rep = pd.read_csv(os.path.join(path_of_data, "all_goc_actuarial_aom_rep_curr/all_goc_actuarial_aom_rep_curr_" + run_date + ".csv"))
df_act_rep = remove_suffix(df_act_rep)
df_ifrs_rep = pd.read_csv(os.path.join(path_of_data, "all_goc_ifrs17_aom_pnl_rep_curr/all_goc_ifrs17_aom_pnl_rep_curr_" + run_date + ".csv"))
df_ifrs_rep = remove_suffix(df_ifrs_rep)
df_gocattributes = pd.read_csv(os.path.join(path_of_data, "all_goc_goc_attributes/all_goc_goc_attributes_" + run_date + ".csv"))


df_gocmapping = df_gocattributes.copy()

try:
    if 't' in df_gocmapping.columns:
        df_gocmapping = df_gocmapping[df_gocmapping['t'] != 0].copy()
    
    if 'iter' not in df_gocmapping.columns:
        df_gocmapping['iter'] = '1'
    
    if 'level' not in df_gocmapping.columns and 'Level' in df_gocmapping.columns:
        df_gocmapping.rename(columns={'Level': 'level'}, inplace=True)
except Exception:
    pass

local_path = f"VAR_IFRS_17_Reports_{run_date}.xlsx"

wb = load_workbook(template_dir)
if not hasattr(wb, "calc_properties") or wb.calc_properties is None:
    wb.calc_properties = CalcProperties(fullCalcOnLoad=True)
else:
    wb.calc_properties.fullCalcOnLoad = True

safe_inject(wb, 'GoC_Attribute', df_gocattributes)
safe_inject(wb, 'GoC_Mapping', df_gocmapping)

if currency_goc and all_gocs:
    safe_inject(wb, 'Actuarial_All_GoC_GoC_Curr', df_act_goc)
    safe_inject(wb, 'IFRS17_All_GoC_GoC_Curr', df_ifrs_goc)

if currency_rep and all_gocs:
    safe_inject(wb, 'Actuarial_All_GoC_Rep_Curr', df_act_rep)
    safe_inject(wb, 'IFRS17_All_GoC_Rep_Curr', df_ifrs_rep)

# Traitement des agrégations
if agg_reports:
    for level in range(1, 6):
        level_var = f'agg_level{level}'
        if locals()[level_var]:
            print(f"Traitement du niveau d'agrégation {level}")
            
            # Créer les données agrégées pour Actuarial
            if currency_rep:
                df_agg_act_rep = create_aggregated_data(df_act_rep, level)
                if not df_agg_act_rep.empty:
                    safe_inject(wb, f'Actuarial_Agg_Level{level}_Rep_Curr', df_agg_act_rep)
                    print(f"✅ Feuille Actuarial_Agg_Level{level}_Rep_Curr créée")
            
            if currency_goc:
                df_agg_act_goc = create_aggregated_data(df_act_goc, level)
                if not df_agg_act_goc.empty:
                    safe_inject(wb, f'Actuarial_Agg_Level{level}_GoC_Curr', df_agg_act_goc)
                    print(f"✅ Feuille Actuarial_Agg_Level{level}_GoC_Curr créée")
            
            # Créer les données agrégées pour IFRS17
            if currency_rep:
                df_agg_ifrs_rep = create_aggregated_data(df_ifrs_rep, level)
                if not df_agg_ifrs_rep.empty:
                    safe_inject(wb, f'IFRS17_Agg_Level{level}_Rep_Curr', df_agg_ifrs_rep)
                    print(f"✅ Feuille IFRS17_Agg_Level{level}_Rep_Curr créée")
            
            if currency_goc:
                df_agg_ifrs_goc = create_aggregated_data(df_ifrs_goc, level)
                if not df_agg_ifrs_goc.empty:
                    safe_inject(wb, f'IFRS17_Agg_Level{level}_GoC_Curr', df_agg_ifrs_goc)
                    print(f"✅ Feuille IFRS17_Agg_Level{level}_GoC_Curr créée")

if var_report and os.path.exists(support_dir) and 'TEMP_ASTRA_VAR' in wb.sheetnames:
    try:
        df_var_formulas = pd.read_csv(support_dir, sep='|')
        df_mapping_clean = df_gocmapping.reset_index(drop=True)
        
        # Traitement All GOCs
        if all_gocs:
            if currency_rep:
                create_var_report(wb, 'TEMP_ASTRA_VAR', 'All_GoC_Rep_Curr', period, df_mapping_clean, df_var_formulas)
                
                if currency_goc and currency_rep:
                    try:
                        rep_sheet = wb[f'VAR_All_GoC_Rep_Curr_{period}']
                        goc_sheet = wb.copy_worksheet(rep_sheet)
                        goc_sheet.title = f'VAR_All_GoC_GoC_Curr_{period}'
                        goc_sheet.cell(row=2, column=3).value = 'All_GoC_GoC_Curr'
                    except Exception:
                        pass
            
            if currency_goc and not (currency_goc and currency_rep):
                create_var_report(wb, 'TEMP_ASTRA_VAR', 'All_GoC_GoC_Curr', period, df_mapping_clean, df_var_formulas)
        
        # Traitement des agrégations
        if agg_reports:
            for level in range(1, 6):
                level_var = f'agg_level{level}'
                if locals()[level_var]:
                    print(f"Création des rapports VAR pour le niveau {level}")
                    
                    # Créer le mapping pour ce niveau d'agrégation
                    df_agg_mapping = create_aggregated_data(df_gocmapping, level)
                    
                    if not df_agg_mapping.empty:
                        if currency_rep:
                            create_var_report(wb, 'TEMP_ASTRA_VAR', f'Agg_Level{level}_Rep_Curr', period, df_agg_mapping, df_var_formulas)
                            print(f"✅ Rapport VAR_Agg_Level{level}_Rep_Curr_{period} créé")
                            
                            if currency_goc:
                                try:
                                    rep_sheet = wb[f'VAR_Agg_Level{level}_Rep_Curr_{period}']
                                    goc_sheet = wb.copy_worksheet(rep_sheet)
                                    goc_sheet.title = f'VAR_Agg_Level{level}_GoC_Curr_{period}'
                                    goc_sheet.cell(row=2, column=3).value = f'Agg_Level{level}_GoC_Curr'
                                    print(f"✅ Rapport VAR_Agg_Level{level}_GoC_Curr_{period} créé")
                                except Exception as e:
                                    print(f"Erreur création GOC pour niveau {level}: {e}")
                        
                        elif currency_goc:
                            create_var_report(wb, 'TEMP_ASTRA_VAR', f'Agg_Level{level}_GoC_Curr', period, df_agg_mapping, df_var_formulas)
                            print(f"✅ Rapport VAR_Agg_Level{level}_GoC_Curr_{period} créé")
    except Exception as e:
        print(f"Erreur dans la création des rapports VAR: {e}")


try:
    if 'Results' in wb.sheetnames:
        ws = wb['Results']
        ws['B2'] = environment
        ws['B3'] = period
        ws['B4'] = user_email
        ws['B5'] = run_date
except Exception:
    pass

wb.save(local_path)
final_path = os.path.join(output_path, local_path)
shutil.move(local_path, final_path)
print(f"✅ Fichier sauvegardé : {final_path}")
